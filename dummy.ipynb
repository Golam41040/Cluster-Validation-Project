{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6918a128-b073-44ef-a2b3-1894490e9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date_Time  Sensor Glucose (mg/dL)\n",
      "0     2017-07-25 12:08:54                   314.0\n",
      "1     2017-07-25 12:13:54                   310.0\n",
      "2     2017-07-25 12:18:54                   309.0\n",
      "3     2017-07-25 12:23:54                   311.0\n",
      "4     2017-07-25 12:28:54                   311.0\n",
      "...                   ...                     ...\n",
      "51170 2018-02-12 12:47:27                   127.0\n",
      "51171 2018-02-12 12:52:27                   126.0\n",
      "51172 2018-02-12 12:57:27                   124.0\n",
      "51173 2018-02-12 13:17:27                   122.0\n",
      "51174 2018-02-12 13:22:27                   118.0\n",
      "\n",
      "[51175 rows x 2 columns]\n",
      "              Date_Time  BWZ Carb Input (grams)  bin\n",
      "1   2017-07-25 10:39:46                    58.0    2\n",
      "2   2017-07-25 18:31:40                   115.0    5\n",
      "5   2017-07-26 12:48:41                    63.0    3\n",
      "6   2017-07-26 19:15:06                    60.0    2\n",
      "7   2017-07-27 05:45:51                    24.0    1\n",
      "..                  ...                     ...  ...\n",
      "740 2018-02-11 12:43:23                    27.0    1\n",
      "743 2018-02-11 18:14:37                     8.0    0\n",
      "744 2018-02-11 20:33:18                    71.0    3\n",
      "745 2018-02-12 02:30:55                    15.0    0\n",
      "746 2018-02-12 09:15:45                    34.0    1\n",
      "\n",
      "[604 rows x 3 columns]\n",
      "        1      2      3      4      5      6      7      8      9      10  \\\n",
      "0    304.0  292.0  281.0  268.0  259.0  255.0  248.0  241.0  231.0  220.0   \n",
      "1     40.0   40.0   40.0   40.0   60.0   71.0   83.0   87.0  100.0  112.0   \n",
      "2    212.0  210.0  204.0  200.0  199.0  201.0  201.0  194.0  188.0  183.0   \n",
      "3    145.0  141.0  137.0  133.0  129.0  124.0  125.0  122.0  123.0  130.0   \n",
      "4     40.0   40.0   46.0   53.0   57.0   57.0   55.0   58.0   70.0   77.0   \n",
      "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "455   61.0   59.0   59.0   60.0   65.0   70.0   82.0  100.0  126.0  133.0   \n",
      "456   57.0   58.0   62.0   74.0  104.0  110.0  126.0  133.0  135.0  141.0   \n",
      "457  209.0  219.0  221.0  221.0  216.0  217.0  215.0  211.0  201.0  200.0   \n",
      "458  106.0  107.0  100.0  104.0  123.0  132.0  129.0  127.0  120.0  132.0   \n",
      "459  150.0  149.0  150.0  151.0  154.0  153.0  158.0  158.0  160.0  159.0   \n",
      "\n",
      "     ...     21     22     23     24     25     26     27     28     29     30  \n",
      "0    ...  270.0  277.0  274.0  269.0  267.0  267.0  274.0  284.0  283.0  278.0  \n",
      "1    ...   67.0   71.0   75.0   74.0   72.0   70.0   67.0   74.0   77.0   81.0  \n",
      "2    ...  210.0  213.0  212.0  216.0  213.0  210.0  210.0  209.0  210.0  209.0  \n",
      "3    ...  200.0  196.0  189.0  183.0  179.0  177.0  173.0  165.0  153.0  152.0  \n",
      "4    ...  132.0  140.0  147.0  157.0  172.0  175.0  183.0  191.0  198.0  200.0  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "455  ...  146.0  153.0  158.0  162.0  169.0  163.0  155.0  136.0  114.0  106.0  \n",
      "456  ...  168.0  174.0  207.0  209.0  206.0  197.0  185.0  191.0  197.0  202.0  \n",
      "457  ...  180.0  184.0  180.0  190.0  196.0  203.0  206.0  212.0  215.0  208.0  \n",
      "458  ...  169.0  176.0  173.0  166.0  162.0  189.0  201.0  200.0  194.0  177.0  \n",
      "459  ...  186.0  193.0  194.0  185.0  184.0  178.0  180.0  174.0  162.0  150.0  \n",
      "\n",
      "[460 rows x 30 columns]\n",
      "[[ 3.  6.  6.  1.  1.  0.  0.]\n",
      " [30. 28. 24. 16.  6.  0.  0.]\n",
      " [20. 16. 15.  5.  6.  0.  0.]\n",
      " [14. 16. 11.  4.  2.  0.  0.]\n",
      " [13. 20. 14.  3.  4.  1.  0.]\n",
      " [22. 29. 21.  6.  3.  1.  0.]\n",
      " [29. 20. 18. 20.  6.  0.  0.]]\n",
      "5065395.229936851\n",
      "9.176198795879202\n",
      "0.32608695652173914\n",
      "[-1  0  1]\n",
      "[[75. 69. 48. 38. 15.  1.  0.]\n",
      " [ 5.  2.  1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [51. 64. 60. 16. 13.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import datetime\n",
    "from scipy.fftpack import fft\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def calc_dbscan_sse(labels, feature_matrix):\n",
    "    sum = 0\n",
    "    cluster_size = max(labels)\n",
    "    for i in range(cluster_size + 1):\n",
    "        x = feature_matrix[labels == i] - feature_matrix[labels == i].mean(axis=0) \n",
    "        sum = np.sum(x ** 2)\n",
    "    return sum\n",
    "\n",
    "def calc_cluster_entropy(gtm):\n",
    "    print(g)\n",
    "    gtm_sum = gtm.sum()\n",
    "    bins = gtm.shape[0]\n",
    "    cluster_entropy = 0\n",
    "    cluster_sum = 0\n",
    "    cluster_entropies = []\n",
    "\n",
    "    for i in range(bins):\n",
    "        cluster_sum = np.sum(gtm[i])\n",
    "        if cluster_sum == 0:\n",
    "            continue\n",
    "        for j in range(bins):\n",
    "            if gtm[i,j] == 0:\n",
    "                continue\n",
    "            col_sum = gtm[i,j] / cluster_sum\n",
    "            entropy = -1 * col_sum * np.log2(col_sum)\n",
    "            cluster_entropy = cluster_entropy + entropy\n",
    "        cluster_entropies.append((cluster_sum / gtm_sum) * cluster_entropy)\n",
    "    return np.sum(cluster_entropies)\n",
    "\n",
    "def calc_cluster_purity(gtm):\n",
    "    gtm_sum = gtm.sum()\n",
    "    bins = gtm.shape[0]\n",
    "    cluster_sum = 0\n",
    "    cluster_purity = 0\n",
    "    cluster_max = 0\n",
    "    cluster_purities = []\n",
    "\n",
    "    for i in range(bins):\n",
    "        cluster_max = np.max(gtm[i])\n",
    "        cluster_sum = np.sum(gtm[i])\n",
    "        if cluster_sum == 0:\n",
    "            continue\n",
    "        cluster_purity = cluster_max / cluster_sum\n",
    "        cluster_purities.append((cluster_sum / gtm_sum) * cluster_purity)\n",
    "    return np.sum(cluster_purities)\n",
    "  \n",
    "\n",
    "def build_ground_truth_cluster_matrix(k, clusters, ground_truth):\n",
    "    cluster_matrix = np.zeros((k, k))\n",
    "    #print(cluster_matrix)\n",
    "    #print(ground_truth)\n",
    "    for i, j in enumerate(ground_truth):\n",
    "        #print(i)\n",
    "        #print(clusters[i])\n",
    "        row = clusters[i]\n",
    "        col = j\n",
    "        cluster_matrix[row][col] += 1\n",
    "    return cluster_matrix\n",
    "\n",
    "def calc_features(df):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, df.shape[0]):\n",
    "        x = df.iloc[i, :].tolist()\n",
    "        features = features.append({\n",
    "            \"Minimum Value\": min(x),\n",
    "            \"Maximum Value\": max(x),\n",
    "            \"Mean of Absolute Values 1\": calc_abs_mean(x[:13]),\n",
    "            \"Mean of Absolute Values 2\": calc_abs_mean(x[13:]),\n",
    "            \"Root Mean Square\": calc_rms(x),\n",
    "            \"Entropy\": calc_entropy(x),\n",
    "            \"Max FFT Amplitude 1\": calc_fft(x[:13])[0],\n",
    "            \"Max FFT Frequency 1\": calc_fft(x[:13])[1],\n",
    "            \"Max FFT Amplitude 2\": calc_fft(x[13:])[0],\n",
    "            \"Max FFT Frequency 2\": calc_fft(x[13:])[1],\n",
    "        },\n",
    "        ignore_index=True\n",
    "        )\n",
    "    return features\n",
    "\n",
    "def calc_abs_mean(df_row):\n",
    "    abs_mean = 0\n",
    "    for i in range(0, len(df_row) - 1):\n",
    "        abs_mean = abs_mean + np.abs(df_row[(i + 1)] - df_row[i])\n",
    "    return abs_mean / len(df_row)\n",
    "\n",
    "def calc_rms(df_row):\n",
    "    rms = 0\n",
    "    for i in range(0, len(df_row) - 1):\n",
    "        rms = rms + np.square(df_row[i])\n",
    "    return np.sqrt(rms / len(df_row))\n",
    "\n",
    "def calc_entropy(df_row):\n",
    "    entropy = 0\n",
    "    if (len(df_row) <= 1):\n",
    "        return 0\n",
    "    else:\n",
    "        value, index = np.unique(df_row, return_counts=True)\n",
    "        ratio = index / len(df_row)\n",
    "        non_zero_ratio = np.count_nonzero(ratio)\n",
    "\n",
    "        if non_zero_ratio <= 1:\n",
    "            return 0\n",
    "        for i in ratio:\n",
    "            entropy -= i * np.log2(i)\n",
    "        return entropy\n",
    "\n",
    "def calc_fft(df_row):\n",
    "    ffourier = fft(df_row)\n",
    "    amplitude = []\n",
    "    frequency = np.linspace(0, len(df_row) * 2/300, len(df_row))\n",
    "\n",
    "    for amp in ffourier:\n",
    "        amplitude.append(np.abs(amp))\n",
    "    \n",
    "    sorted_amplitude = sorted(amplitude)\n",
    "    max_amplitude = sorted_amplitude[(-2)]\n",
    "    max_frequency = frequency.tolist()[amplitude.index(max_amplitude)]\n",
    "    return [max_amplitude, max_frequency]\n",
    "\n",
    "\n",
    "def choose_bin(x, min_carb, total_bins):\n",
    "    partition = float((x - min_carb)/20)\n",
    "    bin =  math.floor(partition)\n",
    "    if bin == total_bins:\n",
    "        bin = bin - 1\n",
    "    return bin\n",
    "\n",
    "def get_df():\n",
    "    insulin_data = pd.read_csv('InsulinData.csv', parse_dates=[['Date','Time']], keep_date_col=True, low_memory=False)\n",
    "    insulin_df = insulin_data[['Date_Time', 'Index', 'BWZ Carb Input (grams)']]\n",
    "    insulin_df.loc[:, 'Index']\n",
    "\n",
    "    glucose_data = pd.read_csv('CGMData.csv', parse_dates=[['Date','Time']], keep_date_col=True, low_memory=False)\n",
    "    glucose_df = glucose_data[['Date_Time', 'Sensor Glucose (mg/dL)']]\n",
    "\n",
    "    return insulin_df, glucose_df\n",
    "\n",
    "def extract_ground_truth(insulin_df, glucose_df):\n",
    "    meals = []\n",
    "    meals_df = pd.DataFrame()\n",
    "    meal_matrix = pd.DataFrame()\n",
    "    two_hours = 60 * 60 * 2\n",
    "    thirty_min = 30 * 60\n",
    "    sensor_time_interval = 30\n",
    "\n",
    "    bin_matrix = []\n",
    "    bins = []\n",
    "    min_carb = 0\n",
    "    max_carb = 0\n",
    "    total_bins = 0\n",
    "\n",
    "    processed_insulin_df = insulin_df.copy()\n",
    "    processed_glucose_df = glucose_df.copy()\n",
    "\n",
    "    # process insulin data\n",
    "    valid_carb_input = processed_insulin_df['BWZ Carb Input (grams)'].notna() & processed_insulin_df['BWZ Carb Input (grams)'] != 0.0\n",
    "    processed_insulin_df = processed_insulin_df.loc[valid_carb_input][['Date_Time', 'BWZ Carb Input (grams)']]\n",
    "    processed_insulin_df.set_index(['Date_Time'], inplace = True)\n",
    "    processed_insulin_df = processed_insulin_df.sort_index().reset_index()\n",
    "    #print(processed_insulin_df)\n",
    "\n",
    "    valid_glucose = processed_glucose_df['Sensor Glucose (mg/dL)'].notna()\n",
    "    processed_glucose_df = processed_glucose_df.loc[valid_glucose][['Date_Time', 'Sensor Glucose (mg/dL)']]\n",
    "    processed_glucose_df.set_index(['Date_Time'], inplace = True)\n",
    "    processed_glucose_df = processed_glucose_df.sort_index().reset_index()\n",
    "    \n",
    "\n",
    "    min_carb = processed_insulin_df['BWZ Carb Input (grams)'].min()\n",
    "    max_carb = processed_insulin_df['BWZ Carb Input (grams)'].max()\n",
    "    total_bins = math.ceil((max_carb - min_carb) / 20)\n",
    "\n",
    "    for i in range(len(processed_insulin_df)):\n",
    "        carb_input = processed_insulin_df['BWZ Carb Input (grams)'][i]\n",
    "        selected_bin = choose_bin(carb_input, min_carb, total_bins)\n",
    "        bins.append(selected_bin)\n",
    "    #print(bins)\n",
    "    processed_insulin_df['bin'] = bins\n",
    "\n",
    "    for i in range(0, len(processed_insulin_df)-1):\n",
    "        time_diff_seconds = (processed_insulin_df.iloc[i + 1]['Date_Time'] - processed_insulin_df.iloc[i]['Date_Time']).total_seconds()\n",
    "        if(time_diff_seconds > two_hours):\n",
    "            meals.append(True)\n",
    "        else:\n",
    "            meals.append(False)\n",
    "        \n",
    "    meals.append(True)\n",
    "    # print(processed_insulin_df)\n",
    "    # print(processed_insulin_df[meals])\n",
    "    meals_df = processed_insulin_df[meals]\n",
    "    \n",
    "    print(processed_glucose_df)\n",
    "    print(meals_df)\n",
    "    \n",
    "    for i in range(len(meals_df)):\n",
    "        lower_bound = meals_df.iloc[i]['Date_Time'] - datetime.timedelta(seconds=thirty_min)\n",
    "        upper_bound = meals_df.iloc[i]['Date_Time'] + datetime.timedelta(seconds=two_hours)\n",
    "        is_within_bounds = (processed_glucose_df['Date_Time'] >= lower_bound) & (processed_glucose_df['Date_Time'] < upper_bound)\n",
    "        bin = meals_df.iloc[i]['bin']\n",
    "        filtered_glucose_df = processed_glucose_df[is_within_bounds]\n",
    "        \n",
    "        if len(filtered_glucose_df.index) == sensor_time_interval:\n",
    "            filtered_glucose_df = filtered_glucose_df.T\n",
    "            filtered_glucose_df.drop('Date_Time', inplace=True)\n",
    "            \n",
    "            filtered_glucose_df.reset_index(drop=True, inplace=True)\n",
    "            filtered_glucose_df.columns = list(range(1, 31))\n",
    "            \n",
    "            meal_matrix = meal_matrix.append(filtered_glucose_df, ignore_index=True)\n",
    "            bin_matrix.append(bin)\n",
    "    \n",
    "    meal_matrix = meal_matrix.apply(pd.to_numeric)\n",
    "    print(meal_matrix)\n",
    "    bin_matrix = np.array(bin_matrix)\n",
    "    #print(meal_matrix)\n",
    "    return meal_matrix, bin_matrix, total_bins\n",
    "\n",
    "\n",
    "def main():\n",
    "    insulin_df, glucose_df = get_df()\n",
    "    meal_matrix, bin_matrix, total_bins = extract_ground_truth(insulin_df, glucose_df)\n",
    "    feature_matrix = calc_features(meal_matrix)\n",
    "    #print(feature_matrix)\n",
    "    feature_matrix = feature_matrix.to_numpy()\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=total_bins, random_state=0).fit(feature_matrix)\n",
    "    kmeans_centroid_locations = kmeans.cluster_centers_\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    #print(kmeans_labels)\n",
    "    kmeans_gtm = build_ground_truth_cluster_matrix(int(total_bins), kmeans_labels, bin_matrix)\n",
    "    #print(kmeans_gtm)\n",
    "    kmeans_sse = kmeans.inertia_\n",
    "    kmeans_entropy = calc_cluster_entropy(kmeans_gtm)\n",
    "    kmeans_purity = calc_cluster_purity(kmeans_gtm)\n",
    "    print(kmeans_sse)\n",
    "    print(kmeans_entropy)\n",
    "    print(kmeans_purity)\n",
    "\n",
    "\n",
    "    \n",
    "    default_epsilon = 50 # retrieved by observing plotted euclidian distances\n",
    "    dbscan = DBSCAN(eps=default_epsilon, min_samples=total_bins, metric=\"euclidean\").fit(feature_matrix)\n",
    "    dbscan_labels = dbscan.labels_\n",
    "    no_of_labels = np.unique(dbscan_labels)\n",
    "    print(no_of_labels)\n",
    "    dbscan_clusters = len(no_of_labels)\n",
    "    dbscan_outliers = np.sum(np.array(dbscan_labels) == -1, axis=0)\n",
    "    dbscan_gtm = build_ground_truth_cluster_matrix(int(total_bins), dbscan_labels, bin_matrix)\n",
    "    dbscan_sse = calc_dbscan_sse(dbscan_labels, scaled_features)\n",
    "    dbscan_entropy = calc_cluster_entropy(dbscan_gtm)\n",
    "    dbscan_purity = calc_cluster_purity(dbscan_gtm)\n",
    "    \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265ba54-2ebc-453b-b14e-9739d7d2c231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
